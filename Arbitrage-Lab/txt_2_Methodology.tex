\section{Methodology}
\subsection{Sparse Synthetic Control}
The core component of our pairs trading strategy involves constructing a synthetic asset that replicates the price behavior of a target security (e.g: AAPL) using a combination of assets from a donor pool. 
Let $\mbf y = [y_{t}]_{t=1}^T\in \R^{T}$ denote the log-price time series of a target asset and $\mbf X = [x_{1t}, ..., x_{Nt}]_{t=1}^T\in\R^{T\times N}$ denote the log-price time series of a donor pool of assets. We construct a synthetic asset ${\mbf y}^*$ through a sparse linear combination
\begin{equation*}
{y}_{t}^* = \sum_{i=1}^N w_i^* x_{it}
.
\end{equation*}
%
The weights $\mbf w^*=[w_1^*, ..., w_N^*]$ are determined via a cardinality-constrained quadratic program
%
\begin{equation*}
\mathbf{w}^* = \argmin_{\mathbf{w} \in \R^{N}} \sum_{t=1}^T \left(y_{t} - \sum_{i=1}^N w_i x_{it}\right)^2 
\quad \text{s.t.} \quad 
\left|
\begin{array}{ll}
	\mbf 1\' \mbf w &= 1 \\
	\norm{\mathbf{w}}_0 &\leq K
\end{array}
\right
.
\end{equation*}
%
where $\|\mathbf{w}\|_0:=\sum_{i=1}^N \I{w_i\neq 0}$ counts the non-zero elements in $\mbf w$. The goal is to enforce sparsity so that only a limited number of assets receive a nonzero weight. The NP-hard cardinality constraint is approximated by the following procedure: 
\begin{enumerate}
\item Solve the full least squares problem
%
\begin{equation*}
\mathbf{w}^{(1)} = \argmin_{\mathbf{w} \in \mathbb{R}^{N}} \norm{\mathbf{y} - \mathbf{X}\mathbf{w}}_2^2
\quad \text{s.t.} \quad \mathbf{1}^\top \mbf w=1.
\end{equation*}
%
\item Select the $K$ largest weights (in absolute value) from $\mbf w^{(1)}$ into
$$\mathcal I:=\{i : |w_i^{(1)}| \t{~among $K$ largests}\}$$
%
\item Solve the restricted program on support $\mathcal I$
%
\begin{equation*}
	\mbf w^{(2)} = \arg \min_{\mbf w_{\mathcal I}\in \mathbb{R}^K} \norm{\mbf y - \mbf X_{\mathcal I}\mbf w_{\mathcal I}}_{2}^{2}
\quad \text{s.t.} \quad 
\mbf 1\' \mbf w_{\mathcal I} = 1
\end{equation*}
%
where $\mbf X_{\mathcal{I}} \in \mathbb{R}^{T \times K}$ is the resricted donor matrix and $\mbf w_{\mathcal{I}} \in \mathbb{R}^{K}$ is the restricted weight vector for the selected assets.
%
\item Construct the full weight vector $\mbf w^* \in \mathbb{R}^{N}$ by embedding the optimized restricted weights back into the original $N$-dimensional space. 
\begin{equation*}
	w^*_i = 
\mycases{llll}{
w^{(2)}_j & \IF  i = \mathcal I_j
\\
0 & \text{otherwise}
}
\end{equation*}
\end{enumerate}


\section{Copula-Based Dependence Modeling}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Introduction to copulas}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and let $R, R^*: \Omega \to \mathbb{R}$ be real-valued random variables representing the target and synthetic log-returns, respectively, 
%where $R_t = y_t - y_{t-1}$ and $R^*_t = y^*_t - y^*_{t-1}$. 
Let $F_R$ and $F_{R^*}$ denote their respective cumulative distribution functions (CDFs).

\begin{definition}[Copula]
A bivariate copula is a function $C: [0,1]^2 \to [0,1]$ satisfying:
\begin{enumerate}
   \item $C(u,0) = C(0,v) = 0$ and $C(u,1) = u$, $C(1,v) = v$ for all $u,v \in [0,1]$ (boundary conditions)
   \item $C(u_2,v_2) - C(u_2,v_1) - C(u_1,v_2) + C(u_1,v_1) \geq 0$ for all $u_1 \leq u_2$, $v_1 \leq v_2$ in $[0,1]$ (2-increasing)
\end{enumerate}
\end{definition}

The fundamental relationship between copulas and joint distributions is established by Sklar's theorem:

\begin{theorem}[Sklar (1959)]
Let $F_{R,R^*}$ be the joint CDF of $(R,R^*)$. Then there exists a copula $C: [0,1]^2 \to [0,1]$ such that
\begin{equation}
   F_{R,R^*}(r,r^*) = C(F_R(r), F_{R^*}(r^*)) \quad \forall r,r^* \in \mathbb{R}.
\end{equation}
If $F_R$ and $F_{R^*}$ are continuous, then $C$ is unique. Conversely, if $C$ is a copula and $F_R$, $F_{R^*}$ are CDFs, then $F_{R,R^*}$ defined above is a joint CDF with margins $F_R$ and $F_{R^*}$.
\end{theorem}
%
When uniqueness holds, the copula can be expressed through the probability integral transform: 
$$
C(u,v) = \mathbb P( F_R(R) \leq u, F_{R^*}(R^*) \leq v) 
\quad \text{for} \quad
(u,v)\in[0,1]^2
.
$$
The corresponding copula density $c:[0,1]^2\to\mathbb R_+$, when it exists, is given by
%When the joint CDF $F_{R,R^*}$ has a density $f_{R,R^*}$ and the copula $C$ is twice differentiable, the copula density is given by
\begin{equation*}
   c(u,v) = \frac{\partial^2 C(u,v)}{\partial u \partial v},
\end{equation*}
and the joint density can be expressed as
\begin{equation*}
   f_{R,R^*}(r,r^*) = c(F_R(r), F_{R^*}(r^*)) f_R(r)f_{R^*}(r^*),
\end{equation*}
where $f_{R,R^*}$ is the joint density and $f_R$ and $f_{R^*}$ are the marginal densities.

This decomposition provides a framework for modeling the dependence structure between the target and synthetic returns independently of their marginal distributions. The implementation involves three stages: (1) nonparametric estimation of the marginal CDFs $F_R$, $F_{R^*}$ , (2) copula calibration from parametric classes $\mathcal{C} = \{C_\theta : \theta \in \Theta\}$ via maximum likelihood estimation, (3) selection of an appropriate copula family 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Marginal Distribution Estimation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The foundation of copula modeling lies in the accurate estimation of marginal distributions for both target and synthetic asset returns. To maintain flexibility and avoid restrictive parametric assumptions, we adopt a non-parametric approach through empirical cumulative distribution functions (ECDFs).
First, we construct logarithmic return series for both assets. Let $y_t$ and $y_t^*$ denote the log-prices of the target and synthetic assets at time $t$, respectively. The log-returns are computed via  
$$
r_t = y_t - y_{t-1} \quad \text{and} \quad r_t^* = y_t^* - y_{t-1}^* \quad \text{for}\ t = 2,\ldots,T,
$$  
establishing stationary time series $\{r_t\}$ and $\{r_t^*\}$ that form the basis for distributional analysis.

Next, we estimate the marginal distributions through linearly interpolated ECDFs. For any $r \in \mathbb{R}$, the empirical distribution functions are given by  
$$
\hat{F}_{R}(r) = \frac{1}{T-1} \sum_{t=2}^T \mathbb{I}(r_t \leq r) \quad \text{and} \quad \hat{F}_{R^*}(r^*) = \frac{1}{T-1} \sum_{t=2}^T \mathbb{I}(r_t^* \leq r^*),
$$  
where $\mathbb{I}(\cdot)$ denotes the usual indicator function. Linear interpolation between observed returns ensures continuity of the distribution functions across their support. To mitigate numerical instabilities during subsequent copula estimation, we constrain the ECDF outputs within $[\epsilon, 1-\epsilon]$ where $\epsilon = 10^{-5}$, thereby avoiding boundary effects at the distribution tails.

The final stage applies the probability integral transform to obtain uniform marginals. Specifically, we compute pseudo-observations  
$$
u_t = \hat{F}_R(r_t) \quad \text{and} \quad v_t = \hat{F}_{R^*}(r_t^*) \quad \text{for}\ t = 2,\ldots,T,
$$  
yielding paired realizations $(\mbf {u,v})=\{(u_t,v_t)\}_{t=2}^T$ that reside in the unit square $[0,1]^2$. This transformation, justified by Sklar's Theorem, effectively decouples the marginal distributions from the dependence structure. The resulting uniform variates serve as canonical inputs for copula specification while preserving the essential dependence characteristics between target and synthetic returns.

%This non-parametric approach to marginal distribution estimation provides several advantages: it circumvents potential misspecification risks from parametric assumptions, maintains consistency with the empirical properties of financial returns, and ensures numerical stability during subsequent copula calibration stages. The procedure aligns with the canonical copula framework by construction, as the uniform pseudo-observations directly satisfy the requirements of Sklar's representation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Copula calibration from parametric classes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The goal of copula fitting is to find the best copula that describes the dependence structure between the returns of the target and synthetic assets. This is done by maximizing the likelihood of the observed data under different copula models. 
%Let $(\mbf u, \mbf v)=[(u_t, v_t)]_{t=1}^T$ be the pseudo-observations obtained through the marginal transformation process, where $u_t = \hat{F}_R(r_t)$ and $v_t = \hat{F}_{R^*}(r_t^*)$. 
We consider parametric copula families $\mathcal{C} = \{C_\theta : \theta \in \Theta\}$ where each copula $C_\theta$ has density
$
%\begin{equation} \label{eq:copula_density_def}
c_\theta(u,v) = \frac{\partial^2 C_\theta}{\partial u \partial v}(u,v)
%\end{equation}
.
$
%\subsubsection{Maximum Likelihood Estimation}
For each candidate copula family, we estimate parameters via constrained maximum likelihood:
%
\begin{equation} \label{eq:mle}
\hat{\theta} = \argmax_{\theta \in \Theta} \ell(\theta | \mbf {u,v}) \quad \text{where} \quad 
\ell(\theta| \mbf {u,v}) = \sum_{t=2}^T \ln c_\theta(u_t, v_t)
.
\end{equation}
%
The optimization is subject to parameter constraints $\Theta$ specific to each copula family:

\begin{itemize}
\item \textbf{Elliptical Copulas:}
   \begin{itemize}
   \item Gaussian: $\Theta = \{\rho \in (-1,1)\}$ with density
   \[
   c_\rho^{Gauss}(u,v) = \frac{1}{\sqrt{1-\rho^2}} \exp\left(-\frac{\zeta_u^2 + \zeta_v^2 - 2\rho\zeta_u\zeta_v}{2(1-\rho^2)} + \frac{\zeta_u^2 + \zeta_v^2}{2}\right)
   \]
   where $\zeta_u = \Phi^{-1}(u)$, $\zeta_v = \Phi^{-1}(v)$ and $\Phi$ is the standard normal CDF.
   
   \item Student-$t$: $\Theta = \{\rho \in (-1,1), \nu > 2\}$ with density
   \[
   c_{\rho,\nu}^{t}(u,v) = \frac{\Gamma\left(\frac{\nu+2}{2}\right)\Gamma\left(\frac{\nu}{2}\right)}{\sqrt{1-\rho^2}\Gamma\left(\frac{\nu+1}{2}\right)^2} 
   \frac{\left(1 + \frac{\zeta_u^2 + \zeta_v^2 - 2\rho\zeta_u\zeta_v}{\nu(1-\rho^2)}\right)^{-(\nu+2)/2}}{\prod_{i\in\{u,v\}} \left(1 + \frac{\zeta_i^2}{\nu}\right)^{-(\nu+1)/2}}
   \]
   where $\zeta_u = t_\nu^{-1}(u)$, $\zeta_v = t_\nu^{-1}(v)$ and $t_\nu$ is the Student-$t$ CDF.
   \end{itemize}	

\item \textbf{Archimedean Copulas:} For generator function $\psi_\theta$, 
\[
C_\theta(u,v) = \psi_\theta(\psi_\theta^{-1}(u) + \psi_\theta^{-1}(v))
\]
    \begin{itemize}
    \item Clayton: $\Theta = (0, \infty)$ with $\psi_\theta(t) = (1 + t)^{-1/\theta}$
    \item Gumbel: $\Theta = [1, \infty)$ with $\psi_\theta(t) = \exp(-t^{1/\theta})$
    \item Frank: $\Theta = \mathbb{R}\setminus\{0\}$ with $\psi_\theta(t) = -\frac{1}{\theta}\ln\left(1 - (1 - e^{-\theta})e^{-t}\right)$
    \item Joe: $\Theta = [1, \infty)$ with $\psi_\theta(t) = 1 - (1 - e^{-t})^{1/\theta}$
    \end{itemize}

\item \textbf{Mixed Copulas:}
    \begin{itemize}
    \item N14: Rotated Clayton-Gumbel mixture with $\Theta \subset \mathbb{R}^2_+$
    \end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Selection of an appropriate copula family}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

After estimating parameters for each candidate copula family $\mathcal{C} = \{C_\theta : \theta \in \Theta\}$, we select the optimal model using information criteria that balance goodness-of-fit against model complexity. Let $\ell(\hat{\theta}|\mbf {u,v}) = \max_{\theta\in\Theta} \sum_{t=2}^T \ln c_{{\theta}}(u_t, v_t)$ be the maximized log-likelihood for a copula with parameter estimate $\hat{\theta}$, where $T$ is the sample size and $k$ is the number of parameters. We evaluate the following information criterions:
$$
\begin{array}{lllll}
\text{\textit{Akaike}} &&& \text{AIC} &= 2k - 2
%\ell(\hat{\theta}) 
\ell(\hat{\theta}|\mbf {u,v})
\\
\text{\textit{Schwarz/Bayesian}} &&& \text{SIC} &= k\ln(T-1) - 2
%\ell(\hat{\theta}) 
\ell(\hat{\theta}|\mbf {u,v})
\\
\text{\textit{Hannan-Quinn}} &&& \text{HQIC} &= 2k\ln(\ln T-1) - 2
%\ell(\hat{\theta})
\ell(\hat{\theta}|\mbf {u,v})
\end{array}
$$

The copula family with the lowest value for a chosen criterion is selected as optimal. These criteria penalize overfitting through the $k$ term while rewarding better fit through the log-likelihood.
%$\ell(\hat{\theta}|\mbf {u,v})$. 
% The SIC provides the strongest penalty for model complexity, making it particularly suitable for financial applications where parsimony is valued.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
 \input{table_1_copula_fit.tex}
 \cref{tab:copula_selection} presents the fitting results for different copula families. 
 %The scatter plots of the empirical and fitted copulas reveal significant lower tail dependence in the returns, consistent with the increased correlation during market downturns. 


%----------------------------------------------------


\section{Pairs Trading Strategy via Mispricing Indices (MI)} \label{sec:mpi_strategy}

In this section, we adapt the mispricing index (MI) strategy from \cite{Xie2016} to our setting, wherein we trade a target asset (with returns $R_t$) against its synthetic counterpart (with returns $R_t^*$). While the strategy might initially appear unconventional, it hinges on interpreting conditional probabilities of daily returns as an evolving measure of relative mispricing. Below, we detail the essential components of the approach and how trading positions are opened and closed.

\subsection{Mispricing Index (MI), Flags and Cumulative Mispricing Index (CMI)}

On each trading day $t$, let $r_t$ and $r_t^*$ respectively denote the realized returns for the target and synthetic assets. We define two conditional mispricing indices,
\begin{align*}
%MI_t
MI_t^{R \mid R^*} 
&= \mathbb{P}(R_t \leq r_t \mid R_t^* = r_t^*)
= 
%\left.
\frac{\partial C_{\hat{\theta}}(F_R(r_t), F_{R^*}(r_t^*))}{\partial F_{R^*}(r_t^*)}
%\right|_{r_t,r_t^*}
,
\\[0.4em]
%MI_t^*
MI_t^{R^* \mid R} 
&= \mathbb{P}(R_t^* \leq r_t^* \mid R_t = r_t)
= 
%\left.
\frac{\partial C_{\hat{\theta}}(F_R(r_t), F_{R^*}(r_t^*))}{\partial F_R(r_t)}
%\right|_{r_t,r_t^*}
.
\end{align*}

The quantity $MI_t^{R \mid R^*}$ measures how ``mispriced'' the target asset appears when conditioned on that day's synthetic return, whereas $MI_t^{R^* \mid R}$ does the same for the synthetic asset when conditioned on the target return.
%
Since a single day's mispricing index reflects only an instantaneous view, we accumulate daily signals over time to gauge how much the returns have gradually driven prices apart (or together). We define a \emph{flag} series for each asset, defined as a running sum of daily deviations from $0.5$\footnote{The subtraction of $0.5$ centers the cumulative sum so that deviations from zero reflect mispricing.}. Let $\text{Flag}_{R}(0)=\text{Flag}_{R^*}(0)=0$, then, for $t=1, ..., T$ we have
%\begin{align*}
$$\begin{array}{llll}
\mathrm{Flag}^{R}_{t} 
&= \mathrm{Flag}^{R}_{t-1} + (MI_t^{R \mid R^*} - 0.5)
&=\sum_{s=1}^t (MI_s^{R \mid R^*} - 0.5),
%&&\text{Flag}_{R}(0) = 0,
\\[0.2em]
\mathrm{Flag}^{R^*}_{t}
&= \mathrm{Flag}^{R^*}_{t-1} + (MI_t^{R^* \mid R} - 0.5)
&= \sum_{s=1}^t (MI_s^{R^* \mid R} - 0.5)
%&&\text{Flag}_{R^*}(0) = 0
.
\end{array}$$
%\end{align*}
%Equivalently, each raw flag is a cumulative sum over the trading horizon:
%\begin{equation}
%\mathrm{Flag}^{R}_{t} = \sum_{s=1}^t (MI_s^{R \mid R^*} - 0.5),
%\qquad
%\mathrm{Flag}^{R^*}_{t}= \sum_{s=1}^t (MI_s^{R^* \mid R} - 0.5).
%\end{equation}
Similar to plotting cumulative returns, these raw flags track the net effect of mispricing signals over time. 
%However, the \emph{real flag} series, $\text{CMI}_R$ and $\text{CMI}_{R^*}$, will be \emph{reset to zero} whenever an open position is fully closed (i.e., after an exit signal). This reset ensures that newly detected mispricings are measured from a fresh baseline rather than mixing with completed trades.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\paragraph{Cumulative Mispricing Index (CMI).}
To prevent the compounding of stale mispricing signals, we formally define a Cumulative Mispricing Index (CMI) as the reset-adjusted flag series through the recursive relationship:
$$
\mathrm{CMI}^{R}_{t} =
\begin{cases}
\mathrm{CMI}^{R}_{t-1} + \bigl(MI_t^{R\mid R^*} - 0.5\bigr), & \text{if no position reset occurs at time } t,\\
0, & \text{if a position is closed at } t,
\end{cases}
$$
$$
\mathrm{CMI}^{R^*}_{t} =
\begin{cases}
\mathrm{CMI}^{R^*}_{t-1} + \bigl(MI_t^{R^*\mid R} - 0.5\bigr), & \text{if no position reset occurs at time } t,\\
0, & \text{if a position is closed at } t,
\end{cases}
$$
where \(\mathrm{CMI}^R_{0}= \mathrm{CMI}^{R^*}_{0}=0\). 
Unlike the raw flags that accrue continuously, each CMI absorbs daily mispricing signals only until a trade is exited, at which point it is reset to zero. This mechanism ensures that any fresh mispricing accumulates from a ``clean slate,'' thereby preventing the influence of past, already-traded mispricing from compounding future signals.
%----------------------------------------------------
% To track active mispricing signals, we introduce the Cumulative Mispricing Index (CMI), which resets upon trading activity. Let $\tau_k$ denote the sequence of times when trades are closed (with $\tau_0 = 0$). For any time $t \in [\tau_k, \tau_{k+1})$, the CMIs are defined as:
%
%\begin{equation*}
%\text{CMI}_{R}(t) = \sum_{s=\tau_k + 1}^t (MI_s^{R \mid R^*} - 0.5),
%\end{equation*}
%
%\begin{equation*}
%\text{CMI}_{R^*}(t) = \sum_{s=\tau_k + 1}^t (MI_s^{R^* \mid R} - 0.5).
%\end{equation*}
%
%These indices maintain a running tally of mispricing signals since the most recent trade closure, providing a cleaner measure of emerging price divergences.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Trading Logic}

We implement a dollar-neutral trading strategy that capitalizes on relative mispricing signals between the target and synthetic assets. The trading rule ($TR$) we employ builds upon the frameworks of \cite{Xie2016} and \cite{Rad2016}, incorporating their key insights about signal combination logic. While \cite{Xie2016} originally proposed an "OR-OR" framework-where trades are initiated when either asset shows mispricing and closed when either asset exhibits correction-\cite{Rad2016} demonstrated that a more conservative "AND-OR" approach yields more robust performance. This latter approach requires concurrent mispricing signals from both assets to open positions while maintaining a sensitive exit strategy where correction in either asset triggers position closure.

Let $D_l$ and $D_u$ denote the lower and upper thresholds for opening positions, and $S_l$ and $S_u$ the lower and upper stop-loss boundaries. Starting with $TR_0=0$, for $t=1,...,T$, the trading rule evolves as follows:

%----------------------------------------------------
\begin{align}\label{eq:trading_rule}
&TR_t(\t{CMI}_t^R, \t{CMI}_t^{R^*}, TR_{t-1}; D_l, D_u, S_l, S_u) 
=
\\[0.2em]
&\mycases{clllll}{
+1 & \IF ~  
(\t{CMI}_t^R \leq  D_l 
~\t{and}~ 
\t{CMI}_t^{R^*} \geq D_u)
\\
-1 & \IF ~ 
(\t{CMI}_t^R \geq D_u 
~\t{and}~ 
\t{CMI}_t^{R^*} \leq D_l)
\\
0 & \IF~
%\t{either} 
$$
%\mycases{llllll}{
\begin{cases}
\biggl\{
TR_{t-1}=1 
~~~\t{and}~ 
\bigl[
(\ub{\t{CMI}_t^R\geq 0 ~\t{or}~ \t{CMI}_t^{R^*}\leq 0}{\t{take profit}})
~\t{or}~
(\ub{\t{CMI}_t^R\leq S_l ~\t{or}~ \t{CMI}_t^{R^*}\geq S_u}{\t{stop loss}})
\bigr]
\biggr\}
,\t{or}
\\
\biggl\{
TR_{t-1}=-1 
~\t{and}~ 
\bigl[
(\ub{\t{CMI}_t^R\leq 0 ~\t{or}~ \t{CMI}_t^{R^*}\geq 0}{\t{take profit}})
~\t{or}~
(\ub{\t{CMI}_t^R\geq S_u ~\t{or}~ \t{CMI}_t^{R^*}\leq S_l}{\t{stop loss}})
\bigr]
\biggr\}
%}
\end{cases}
$$
\\
TR_{t-1} & \t{otherwise}
}
\end{align}
%----------------------------------------------------

That is, at the beginning of each trading day \(t\), observe the current values of both mispricing indicators, \(\mathrm{CMI}_t^R\) (for the target asset) and \(\mathrm{CMI}_t^{R^*}\) (for the synthetic). The trading rule \(TR_t\) can take one of three values: \(+1\), \(-1\), or \(0\), indicating a \qquote{long-short}, \qquote{short-long}, or \qquote{flat} position, respectively. When no position is open (i.e., \(TR_{t-1} = 0\)), the rule opens a position only if there is simultaneous mispricing in both assets according to the thresholds \(D_l\) and \(D_u\). 
%----------------------------------------------------
Specifically,
\begin{itemize}
  \item \qquote{Long target/Short synthetic} (+1): Entered when both CMIs indicate the target asset is underpriced relative to the synthetic ($\text{CMI}_t^R \leq D_l$ \textbf{and} $\text{CMI}_t^{R^*} \geq D_u$).
  \item \qquote{Short target/Long synthetic} (-1): Entered when both CMIs indicate the target asset is overpriced relative to the synthetic ($\text{CMI}_t^R \geq D_u$ \textbf{and} $\text{CMI}_t^{R^*} \leq D_l$).
\end{itemize} 
%----------------------------------------------------
%if \(\mathrm{CMI}_t^R\) falls below \(D_l\) at the same time that \(\mathrm{CMI}_t^{R^*}\) rises above \(D_u\), then \(TR_t\) is set to \(+1\). Conversely, if \(\mathrm{CMI}_t^R\) rises above \(D_u\) while \(\mathrm{CMI}_t^{R^*}\) falls below \(D_l\), \(TR_t\) is set to \(-1\).

Once a position is open (either \(TR_{t-1} = +1\) or \(TR_{t-1} = -1\)), the logic checks each day whether the mispricing has corrected enough to trigger a take-profit condition or crossed critical boundaries that trigger a stop-loss. These checks apply to either of the two mispricing indices, so if correction or a stop-loss occurs in any one of them, the entire position is closed. Mathematically, this is captured by the \qquote{OR} clauses in the formula, which evaluate whether \(\mathrm{CMI}_t^R\) or \(\mathrm{CMI}_t^{R^*}\) has crossed the zero line (for take-profit) or moved beyond the \((S_l, S_u)\) band (for stop-loss). If one of these events occurs, then \(TR_t\) is set to \(0\), and the mispricing indices are both reset to zero for the next trading day. 
%----------------------------------------------------
%Specifically:
%\begin{itemize}
%\item \textit{Exit position} (0): An existing position is closed under two scenarios:
%\begin{itemize}
%  \item Take profit: When \textbf{either} CMI reverts to zero, suggesting the mispricing has been corrected
%  \item Stop loss: When \textbf{either} CMI reaches its respective stop-loss boundary
%\end{itemize}
%\end{itemize}
%----------------------------------------------------
If neither a take-profit nor a stop-loss threshold is met, then the position remains unchanged, meaning \(TR_t\) simply inherits the previous value \(TR_{t-1}\).

Intuitively, when both indicators are simultaneously misaligned (one significantly high and the other significantly low), the strategy deems it a strong signal to open a dollar-neutral position that is long the \qquote{undervalued} side and short the \qquote{overvalued} side. As soon as either index crosses back toward zero (suggesting partial correction of that asset's mispricing) or breaches a stop-loss boundary (indicating that the trade is moving unfavorably), the position is liquidated. This \qquote{AND-OR} logic helps filter out noise in the daily movements and more reliably captures episodes in which both assets appear to be drifting apart (opening a trade) and then swiftly catches at least one side reverting (closing the trade).

As in \cite{Xie2016}, we set $(D_l, D_u)=(-0.6,0.6)$ and $(S_u,S_l)=(-2,2)$ and we will explore other parametric choices in the robustness checks.


%The intuition behind these rules is that the cumulative mispricing captured by the flag series reflects how returns may drive prices apart or together over time. Because trading is ultimately conducted on prices, it becomes necessary to integrate the daily return information in a cumulative measure and to reset it upon entering a new trade.


%----------------------------------------------------
%----------------------------------------------------
%Starting with $TR_0=0$, the strategy generates three possible positions at each time $t=1,...,T$:
%\begin{itemize}
%  \item Long target/Short synthetic (+1): Entered when both CMIs indicate the target asset is underpriced relative to the synthetic ($\text{CMI}_t^R \leq D_l$ \textbf{and} $\text{CMI}_t^{R^*} \geq D_u$).
%  \item Short target/Long synthetic (-1): Entered when both CMIs indicate the target asset is overpriced relative to the synthetic ($\text{CMI}_t^R \geq D_u$ \textbf{and} $\text{CMI}_t^{R^*} \leq D_l$).
%  \item Exit position (0): An existing position is closed under two scenarios:
%\begin{itemize}
%  \item Take profit: When \textbf{either} CMI reverts to zero, suggesting the mispricing has been corrected
%  \item Stop loss: When \textbf{either} CMI reaches its respective stop-loss boundary
%\end{itemize}
%\end{itemize}
% If none of the conditions for opening or closing a position are met, the previous trading signal ($TR_{t-1}$) is maintained. Formally, the trading rule is defined as:
%----------------------------------------------------
